{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISYR</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>CBSA2010</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>MARSTAT</th>\n",
       "      <th>SERVICES</th>\n",
       "      <th>DETCRIM</th>\n",
       "      <th>LOS</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRNQFLG</th>\n",
       "      <th>BARBFLG</th>\n",
       "      <th>SEDHPFLG</th>\n",
       "      <th>INHFLG</th>\n",
       "      <th>OTCFLG</th>\n",
       "      <th>OTHERFLG</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>IDU</th>\n",
       "      <th>ALCDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191553576</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191465214</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191443889</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191409377</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191479567</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISYR       CASEID  STFIPS  CBSA2010  EDUC  MARSTAT  SERVICES  DETCRIM  \\\n",
       "0   2019  20191553576       2        -9     4        1         7       -9   \n",
       "1   2019  20191465214       2        -9     3        1         7       -9   \n",
       "2   2019  20191443889       2        -9     2        1         7       -9   \n",
       "3   2019  20191409377       2        -9     3        1         7       -9   \n",
       "4   2019  20191479567       2        -9     3        3         7       -9   \n",
       "\n",
       "   LOS  PSOURCE  ...  TRNQFLG  BARBFLG  SEDHPFLG  INHFLG  OTCFLG  OTHERFLG  \\\n",
       "0   37        1  ...        0        0         0       0       0         0   \n",
       "1   35        1  ...        0        0         0       0       0         0   \n",
       "2   35        1  ...        0        0         0       0       0         0   \n",
       "3   37        1  ...        0        0         0       0       0         0   \n",
       "4   37        1  ...        0        0         0       0       0         0   \n",
       "\n",
       "   DIVISION  REGION  IDU  ALCDRUG  \n",
       "0         9       4    0        1  \n",
       "1         9       4    0        3  \n",
       "2         9       4    0        3  \n",
       "3         9       4    0        3  \n",
       "4         9       4    0        1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tedsd_puf_2019.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASON\n",
       "1    1095432\n",
       "0     627071\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "# from conversation with \"house of Hope recovery\" class 4 which is \"transfer to a different facility\" would also be considered a success.\n",
    "for value in df1['REASON']:\n",
    "    if value == 1:\n",
    "        value = value\n",
    "    elif value == 4:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['REASON'] = df1['REASON'].replace(4, 1)\n",
    "df1['REASON'] = df1['REASON'].replace(2, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(3, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(5, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(6, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(7, 0)\n",
    "df1['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB1\n",
      "0    1145410\n",
      "1     577093\n",
      "Name: count, dtype: int64\n",
      "SUB1_D\n",
      "0    1153301\n",
      "1     569202\n",
      "Name: count, dtype: int64\n",
      "SUB2\n",
      "1    959459\n",
      "0    763044\n",
      "Name: count, dtype: int64\n",
      "SUB2_D\n",
      "1    990170\n",
      "0    732333\n",
      "Name: count, dtype: int64\n",
      "SUB3\n",
      "1    1278583\n",
      "0     443920\n",
      "Name: count, dtype: int64\n",
      "SUB3_D\n",
      "1    1403980\n",
      "0     318523\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# time to clean up the data starting with SUB1_D \n",
    "# alcohol could be a success, mmj could be a success\n",
    "for value in df1['SUB1_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(14, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(16, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(18, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(12, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(13, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(2, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(3, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(4, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(5, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(6, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(7, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(8, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(9, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(10, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(11, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(15, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(17, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB1'] = df1['SUB1'].replace(14, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(16, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(18, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(12, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(13, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(2, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(3, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(4, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(5, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(6, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(7, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(8, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(9, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(10, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(11, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(15, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(17, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(19, 0)\n",
    "\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(14, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(16, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(18, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(12, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(13, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(2, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(3, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(4, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(5, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(6, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(7, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(8, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(9, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(10, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(11, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(15, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(17, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB2'] = df1['SUB2'].replace(14, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(16, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(18, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(12, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(13, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(2, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(3, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(4, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(5, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(6, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(7, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(8, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(9, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(10, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(11, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(15, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(17, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(19, 0)\n",
    "\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(14, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(16, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(18, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(12, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(13, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(2, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(3, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(4, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(5, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(6, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(7, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(8, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(9, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(10, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(11, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(15, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(17, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB3'] = df1['SUB3'].replace(14, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(16, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(18, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(12, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(13, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(2, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(3, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(4, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(5, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(6, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(7, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(8, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(9, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(10, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(11, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(15, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(17, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(19, 0)\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB1']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "for value in df1['SUB2_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB2']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "for value in df1['SUB3_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB3']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1'] = df1['SUB1'].replace(-9, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(-9, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(-9, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "print(df1['SUB1'].value_counts())\n",
    "print(df1['SUB1_D'].value_counts())\n",
    "print(df1['SUB2'].value_counts())\n",
    "print(df1['SUB2_D'].value_counts())\n",
    "print(df1['SUB3'].value_counts())\n",
    "print(df1['SUB3_D'].value_counts())\n",
    "\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# # In column SUB2 replace -9 with 19\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 19)\n",
    "# print(df1['SUB2'].value_counts())\n",
    "# # In column SUB2_D replace -9 with 19\n",
    "# # df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 19)\n",
    "# print(df1['SUB2_D'].value_counts())\n",
    "# # In column SUB3 replace -9 with 19\n",
    "# # df1['SUB3'] = df1['SUB3'].replace(-9, 19)\n",
    "# print(df1['SUB3'].value_counts())\n",
    "# # In column SUB3_D replace -9 with 0\n",
    "# # df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "# print(df1['SUB3_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1_D, FREQ2_D, FREQ3_D\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1_D'] = df1['FREQ1_D'].replace(-9, 1)\n",
    "df1['FREQ2_D'] = df1['FREQ2_D'].replace(-9, 1)\n",
    "df1['FREQ3_D'] = df1['FREQ3_D'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1, FREQ2, FREQ3\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1'] = df1['FREQ1'].replace(-9, 1)\n",
    "df1['FREQ2'] = df1['FREQ2'].replace(-9, 1)\n",
    "df1['FREQ3'] = df1['FREQ3'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'CASEID'\n",
    "df1['CASEID'].notna().value_counts()\n",
    "# CASEID has no null values and does need info filled\n",
    "# we can drop this field\n",
    "df1 = df1.drop(columns=\"CASEID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'AGE'\n",
    "df1['AGE'].notna().value_counts()\n",
    "# AGE has no null values and does need info filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'GENDER'\n",
    "# gender is not a columns where we can fill in the data and not decrease the accuracy. so for all -9 values I am replacing with 0\n",
    "df1['GENDER'] = df1['GENDER'].replace(-9, 0)\n",
    "df1['GENDER'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DISYR'\n",
    "df1['DISYR'].notna().value_counts()\n",
    "# DISYR has no null values and does need info filled\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DISYR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RACE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'RACE'\n",
    "# for race, '7' indicateds 'other single race  so for all -9 values i replaces them with 7\n",
    "df1['RACE'] = df1['RACE'].replace(-9, 7)\n",
    "df1['RACE'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETHNIC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'ETHNIC'\n",
    "# for ETHNIC, '4' indicateds 'other single race  so for all -9 values I replaced them with 4\n",
    "df1['ETHNIC'] = df1['ETHNIC'].replace(-9, 4)\n",
    "df1['ETHNIC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARSTAT\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'MARSTAT'\n",
    "# for MARSTAT, hard to determine what to fill -9 with so filling with 0 for now\n",
    "df1['MARSTAT'] = df1['MARSTAT'].replace(-9, 0)\n",
    "df1['MARSTAT'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDUC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EDUC'\n",
    "# for EDUC, hard to determine what to fill -9 with. options are 1-5 so filling with 2 as it seems like a fair average\n",
    "df1['EDUC'] = df1['EDUC'].replace(-9, 2)\n",
    "df1['EDUC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMPLOY\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EMPLOY' and 'EMPLOY_D'\n",
    "# for EMPLOY, hard to determine what to fill -9 with. options are 1-4. filling with 2 for now since if the data is missing is seems like that would indicate 'unemployed'\n",
    "df1['EMPLOY'] = df1['EMPLOY'].replace(-9, 0)\n",
    "df1['EMPLOY_D'] = df1['EMPLOY_D'].replace(-9, 0)\n",
    "df1['EMPLOY'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DETNLF' and 'DETNLF_D'\n",
    "# for DETNLF, its just details on the previous columns not in labor force option so im replacing missing values with 0 as to not affect the results as much. we may want to drop this column\n",
    "# df1['DETNLF'] = df1['DETNLF'].replace(-9, 0)\n",
    "# df1['DETNLF_D'] = df1['DETNLF_D'].replace(-9, 0)\n",
    "# df1['DETNLF'].notna().value_counts()\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DETNLF\")\n",
    "df1 = df1.drop(columns=\"DETNLF_D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREG\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PREG'\n",
    "# for PREG, -9 most likely indicates male patients. replacing with 0 as to not affect the results as much. \n",
    "df1['PREG'] = df1['PREG'].replace(-9, 2)\n",
    "df1['PREG'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VET\n",
       "2    1679845\n",
       "1      42658\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'VET'\n",
    "# for VET, -9 most likely indicates not a veteren so im replacing -9 with 2 for 'no'\n",
    "df1['VET'] = df1['VET'].replace(-9, 2)\n",
    "df1['VET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIVARAG\n",
       "3    1013787\n",
       "1     436264\n",
       "2     272452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'LIVARAG'\n",
    "# for LIVARAG, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['LIVARAG'] = df1['LIVARAG'].replace(-9, 1)\n",
    "df1['LIVARAG_D'] = df1['LIVARAG_D'].replace(-9, 1)\n",
    "df1['LIVARAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMINC\n",
       "4    855478\n",
       "5    397327\n",
       "1    312986\n",
       "2     81605\n",
       "3     75107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PRIMINC'\n",
    "# for PRIMINC, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['PRIMINC'] = df1['PRIMINC'].replace(-9, 4)\n",
    "df1['PRIMINC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARRESTS_D\n",
       "0    1643399\n",
       "1      61908\n",
       "2      17196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'ARRESTS' and 'ARRESTS_D'\n",
    "# for 'ARRESTS' and 'ARRESTS_D', 0 indicates none so im setting -9 to none as that seems most likely to be the case if the information is missing\n",
    "df1['ARRESTS'] = df1['ARRESTS'].replace(-9, 0)\n",
    "df1['ARRESTS_D'] = df1['ARRESTS_D'].replace(-9, 0)\n",
    "df1['ARRESTS'].value_counts()\n",
    "df1['ARRESTS_D'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with ' STFIPS'\n",
    "# for ' STFIPS', there are no null values in this column but we may want to remove it because the large values could through the accuracy off\n",
    "df1['STFIPS'].notna().value_counts()\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"STFIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGION\n",
       "1    532413\n",
       "3    505555\n",
       "4    378260\n",
       "2    303497\n",
       "0      2778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'REGION'\n",
    "# for 'REGION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['REGION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "2    372934\n",
       "5    331617\n",
       "8    229376\n",
       "1    159479\n",
       "4    152327\n",
       "3    151170\n",
       "9    148884\n",
       "6    100660\n",
       "7     73278\n",
       "0      2778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DIVISION'\n",
    "# for 'DIVISION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERVICES_D\n",
       "7    884266\n",
       "2    240303\n",
       "6    235771\n",
       "4    179737\n",
       "5    121470\n",
       "1     43446\n",
       "8     13267\n",
       "3      4243\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'SERVICES and SERVICES_D'\n",
    "# for 'SERVICES and SERVICES_D', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data for the questions we are trying to answer\n",
    "df1['SERVICES'].value_counts()\n",
    "df1['SERVICES_D'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYWAIT\n",
       "0    1469735\n",
       "1     175018\n",
       "2      34722\n",
       "3      26618\n",
       "4      16410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DAYWAIT'\n",
    "# for 'DAYWAIT', its seems safe to replace a value of missing data with a value of '0' to indicate that they didnt wait\n",
    "df1['DAYWAIT'] = df1['DAYWAIT'].replace(-9, 0)\n",
    "df1['DAYWAIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHUSE\n",
       "2    1327459\n",
       "1     216239\n",
       "0     178805\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'METHUSE'\n",
    "# for 'METHUSE', its seems safe to replace a value of missing data with a value of 'none'\n",
    "df1['METHUSE'] = df1['METHUSE'].replace(-9, 0)\n",
    "df1['METHUSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'LOS'\n",
    "# for 'LOS', stands for length of stay this data seems irrelivent to the questions we are trying to answer so I suggest dropping the column to perserve prediction accuracy\n",
    "# 1-30, 31-45, 46-60, 61-90, 91-120, 121-180, 181-365, more than\n",
    "def los_to_category(days):\n",
    "    if days <= 30:\n",
    "        return 1\n",
    "    elif days <= 31:\n",
    "        return 2\n",
    "    elif days <= 32:\n",
    "        return 3\n",
    "    elif days <= 33:\n",
    "        return 4\n",
    "    elif days <= 34:\n",
    "        return 5\n",
    "    elif days <= 35:\n",
    "        return 6\n",
    "    elif days <= 36:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "# Test cases\n",
    "\n",
    "# df1['LOS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(los_to_category(15))  # Expected output: 1\n",
    "print(los_to_category(35))  # Expected output: 2\n",
    "print(los_to_category(50))  # Expected output: 3\n",
    "print(los_to_category(70))  # Expected output: 4\n",
    "print(los_to_category(100))  # Expected output: 5\n",
    "print(los_to_category(150))  # Expected output: 6\n",
    "print(los_to_category(200))  # Expected output: 7\n",
    "print(los_to_category(400))  # Expected output: 8\n",
    "print(los_to_category(-5))  # Expected output: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['LOS'] = df1['LOS'].apply(los_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOS\n",
       "1    934659\n",
       "4    140555\n",
       "7    128974\n",
       "5    114387\n",
       "6    114266\n",
       "2    111830\n",
       "8     93500\n",
       "3     84332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['LOS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with PSOURCE: Referral source\n",
    "# for 'PSOURCE' this doesnt seem to me to be relevant data so im replacing -9 with 1 for now to indicate that it was self motivated\n",
    "df1['PSOURCE'] = df1['PSOURCE'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with DETCRIM: Detailed criminal justice referral\n",
    "# for 'DETCRIM' im replacing -9 with 0 for now. most of this data is missing. we may want to drop this column\n",
    "df1['DETCRIM'] = df1['DETCRIM'].replace(-9, 0)\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DETCRIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with NOPRIOR: Previous substance use treatment episodes\n",
    "# for 'NOPRIOR' im replacing -9 with 0 for now. its could go either way. we will ask clients\n",
    "df1['NOPRIOR'] = df1['NOPRIOR'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with ROUTE1: Route of administration (primary)\n",
    "# time to clean up the data with ROUTE2: Route of administration (secondary)\n",
    "# time to clean up the data with ROUTE3: Route of administration (tertiary)\n",
    "# for 'ROUTE1' im replacing -9 with 5 for now to indicate 'other'. its could go either way. we will ask clients\n",
    "df1['ROUTE1'] = df1['ROUTE1'].replace(-9, 5)\n",
    "df1['ROUTE2'] = df1['ROUTE2'].replace(-9, 5)\n",
    "df1['ROUTE3'] = df1['ROUTE3'].replace(-9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRSTUSE2\n",
      "3    1067078\n",
      "2     170892\n",
      "4     153705\n",
      "7     103384\n",
      "5      95617\n",
      "6      78339\n",
      "1      53488\n",
      "Name: count, dtype: int64\n",
      "FRSTUSE3\n",
      "3    1464306\n",
      "2      78630\n",
      "4      57055\n",
      "7      37209\n",
      "5      32205\n",
      "6      27655\n",
      "1      25443\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# time to clean up the data with FRSTUSE1: Age at first use (primary)\n",
    "# FRSTUSE1 is a column where its hard to determine what a value of -9 should be replaced with so im replacing it with 0 for now to have less of an impact on the data\n",
    "df1['FRSTUSE1'] = df1['FRSTUSE1'].replace(-9, 3)\n",
    "# adding Beau's code\n",
    "# In column FRSTUSE2 replace -9 with 0\n",
    "df1['FRSTUSE2'] = df1['FRSTUSE2'].replace(-9, 3)\n",
    "print(df1['FRSTUSE2'].value_counts())\n",
    "# In column FRSTUSE3 replace -9 with 0\n",
    "df1['FRSTUSE3'] = df1['FRSTUSE3'].replace(-9, 3)\n",
    "print(df1['FRSTUSE3'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB2\n",
      "1    959459\n",
      "0    763044\n",
      "Name: count, dtype: int64\n",
      "SUB2_D\n",
      "1    990170\n",
      "0    732333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column SUB2 replace -9 with 19\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 19)\n",
    "print(df1['SUB2'].value_counts())\n",
    "# In column SUB2_D replace -9 with 19\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 19)\n",
    "print(df1['SUB2_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB3\n",
      "1    1278583\n",
      "0     443920\n",
      "Name: count, dtype: int64\n",
      "SUB3_D\n",
      "1    1403980\n",
      "0     318523\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column SUB3 replace -9 with 19\n",
    "df1['SUB3'] = df1['SUB3'].replace(-9, 19)\n",
    "print(df1['SUB3'].value_counts())\n",
    "# In column SUB3_D replace -9 with 0\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "print(df1['SUB3_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUTE3\n",
      "5    1365958\n",
      "2     154215\n",
      "1     122303\n",
      "3      48044\n",
      "4      31983\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column ROUTE3 replace -9 with 0\n",
    "df1['ROUTE3'] = df1['ROUTE3'].replace(-9, 0)\n",
    "print(df1['ROUTE3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSMCRIT\n",
      "5     790823\n",
      "4     289535\n",
      "8     143441\n",
      "19    125445\n",
      "7      82105\n",
      "6      56213\n",
      "9      52972\n",
      "2      40101\n",
      "10     39565\n",
      "3      29130\n",
      "11     23297\n",
      "12     17972\n",
      "1      12628\n",
      "13      7786\n",
      "15      5239\n",
      "17      2246\n",
      "14      2181\n",
      "16      1490\n",
      "18       334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column DSMCRIT replace -9 with 0\n",
    "df1['DSMCRIT'] = df1['DSMCRIT'].replace(-9, 5)\n",
    "print(df1['DSMCRIT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSYPROB\n",
      "1    899280\n",
      "2    823223\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column PSYPROB replace -9 with 1\n",
    "df1['PSYPROB'] = df1['PSYPROB'].replace(-9, 1)\n",
    "print(df1['PSYPROB'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMPAY\n",
      "1    1038444\n",
      "4     389616\n",
      "5     162022\n",
      "7      49127\n",
      "2      44071\n",
      "6      20758\n",
      "3      18465\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column PRIMPAY replace -9 with 1\n",
    "df1['PRIMPAY'] = df1['PRIMPAY'].replace(-9, 1)\n",
    "print(df1['PRIMPAY'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ_ATND_SELF_HELP\n",
      "1    1037604\n",
      "3     389036\n",
      "4     126267\n",
      "2     104522\n",
      "5      65074\n",
      "Name: count, dtype: int64\n",
      "FREQ_ATND_SELF_HELP_D\n",
      "1    859331\n",
      "3    452977\n",
      "4    186509\n",
      "2    115895\n",
      "5    107791\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column FREQ_ATND_SELF_HELP replace -9 with 0\n",
    "df1['FREQ_ATND_SELF_HELP'] = df1['FREQ_ATND_SELF_HELP'].replace(-9, 3)\n",
    "print(df1['FREQ_ATND_SELF_HELP'].value_counts())\n",
    "# In column FREQ_ATND_SELF_HELP_D replace -9 with 0\n",
    "df1['FREQ_ATND_SELF_HELP_D'] = df1['FREQ_ATND_SELF_HELP_D'].replace(-9, 3)\n",
    "print(df1['FREQ_ATND_SELF_HELP_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALCFLG       0.025359\n",
       "LIVARAG_D    0.026111\n",
       "FREQ1_D      0.029926\n",
       "HLTHINS      0.032940\n",
       "ROUTE3       0.036662\n",
       "EMPLOY_D     0.040257\n",
       "ETHNIC       0.057235\n",
       "SUB1_D       0.066446\n",
       "PRIMPAY      0.067499\n",
       "AGE          0.068791\n",
       "ROUTE2       0.071289\n",
       "SUB1         0.073811\n",
       "SUB2         0.080155\n",
       "SUB3_D       0.088915\n",
       "METHUSE      0.096050\n",
       "SUB3         0.102280\n",
       "DIVISION     0.128182\n",
       "SUB2_D       0.136620\n",
       "REGION       0.153238\n",
       "REASON       1.000000\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason = df1['REASON']\n",
    "df1_corr = df1.corr()\n",
    "df1_corr.unstack().sort_values()\n",
    "variable = df1_corr['REASON'].sort_values()\n",
    "variable.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe with only the top correlated farctors left\n",
    "trimmed = df1[['SUB1_D', 'FREQ1_D', 'ARRESTS', 'ARRESTS_D', 'LIVARAG', 'EMPLOY_D', 'LIVARAG_D', 'EDUC', 'SUB1', 'FREQ_ATND_SELF_HELP', 'EMPLOY', 'ROUTE1', 'IDU', 'SERVICES', 'SERVICES_D', 'VET', 'FRSTUSE1', 'MARSTAT', 'REASON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"REASON\"]\n",
    "X = df1.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train score: 0.1820472417433483\n",
      "Test Score: 0.18229784593246867\n",
      "\n",
      "Model: KNeighborsRegressor\n",
      "Train score: 0.5484424945764218\n",
      "Test Score: 0.3135207736949889\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.926780461064927\n",
      "Test Score: 0.4983952966864844\n",
      "\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 0.9953213845787849\n",
      "Test Score: 0.5015936690426299\n",
      "\n",
      "Model: AdaBoostRegressor\n",
      "Train score: 0.17502851311555667\n",
      "Test Score: 0.17721880330641393\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# test_model(LinearRegression(), data)\n",
    "# test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "# test_model(AdaBoostRegressor(), data)\n",
    "# test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HLTHINS    -0.106469\n",
       "PRIMINC    -0.098816\n",
       "LOS        -0.084553\n",
       "ALCFLG     -0.078218\n",
       "PRIMPAY    -0.059634\n",
       "AGE        -0.051736\n",
       "DETNLF     -0.051458\n",
       "CASEID     -0.042650\n",
       "DIVISION   -0.030955\n",
       "DAYWAIT    -0.014194\n",
       "DETCRIM    -0.006041\n",
       "BARBFLG    -0.003555\n",
       "DSMCRIT    -0.002691\n",
       "METHUSE    -0.001831\n",
       "TRNQFLG     0.002683\n",
       "INHFLG      0.003850\n",
       "OTCFLG      0.005075\n",
       "PCPFLG      0.006215\n",
       "HALLFLG     0.007157\n",
       "REGION      0.009529\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1[\"REASON\"]\n",
    "X = df1.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "logistic_regression_model = ExtraTreesRegressor()\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "train = (f\"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}\")\n",
    "test = (f\"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}\")\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "print(accuracy_score(y_test, testing_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
