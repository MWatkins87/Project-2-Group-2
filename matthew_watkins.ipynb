{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor,  RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISYR</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>CBSA2010</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>MARSTAT</th>\n",
       "      <th>SERVICES</th>\n",
       "      <th>DETCRIM</th>\n",
       "      <th>LOS</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRNQFLG</th>\n",
       "      <th>BARBFLG</th>\n",
       "      <th>SEDHPFLG</th>\n",
       "      <th>INHFLG</th>\n",
       "      <th>OTCFLG</th>\n",
       "      <th>OTHERFLG</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>IDU</th>\n",
       "      <th>ALCDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191553576</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191465214</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191443889</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191409377</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191479567</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISYR       CASEID  STFIPS  CBSA2010  EDUC  MARSTAT  SERVICES  DETCRIM  \\\n",
       "0   2019  20191553576       2        -9     4        1         7       -9   \n",
       "1   2019  20191465214       2        -9     3        1         7       -9   \n",
       "2   2019  20191443889       2        -9     2        1         7       -9   \n",
       "3   2019  20191409377       2        -9     3        1         7       -9   \n",
       "4   2019  20191479567       2        -9     3        3         7       -9   \n",
       "\n",
       "   LOS  PSOURCE  ...  TRNQFLG  BARBFLG  SEDHPFLG  INHFLG  OTCFLG  OTHERFLG  \\\n",
       "0   37        1  ...        0        0         0       0       0         0   \n",
       "1   35        1  ...        0        0         0       0       0         0   \n",
       "2   35        1  ...        0        0         0       0       0         0   \n",
       "3   37        1  ...        0        0         0       0       0         0   \n",
       "4   37        1  ...        0        0         0       0       0         0   \n",
       "\n",
       "   DIVISION  REGION  IDU  ALCDRUG  \n",
       "0         9       4    0        1  \n",
       "1         9       4    0        3  \n",
       "2         9       4    0        3  \n",
       "3         9       4    0        3  \n",
       "4         9       4    0        1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tedsd_puf_2019.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASON\n",
       "1    1095432\n",
       "0     627071\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "# from conversation with \"house of Hope recovery\" class 4 which is \"transfer to a different facility\" would also be considered a success.\n",
    "for value in df1['REASON']:\n",
    "    if value == 1:\n",
    "        value = value\n",
    "    elif value == 4:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['REASON'] = df1['REASON'].replace(4, 1)\n",
    "df1['REASON'] = df1['REASON'].replace(2, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(3, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(5, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(6, 0)\n",
    "df1['REASON'] = df1['REASON'].replace(7, 0)\n",
    "df1['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB1\n",
      "0    1145410\n",
      "1     577093\n",
      "Name: count, dtype: int64\n",
      "SUB1_D\n",
      "0    1153301\n",
      "1     569202\n",
      "Name: count, dtype: int64\n",
      "SUB2\n",
      "1    959459\n",
      "0    763044\n",
      "Name: count, dtype: int64\n",
      "SUB2_D\n",
      "1    990170\n",
      "0    732333\n",
      "Name: count, dtype: int64\n",
      "SUB3\n",
      "1    1278583\n",
      "0     443920\n",
      "Name: count, dtype: int64\n",
      "SUB3_D\n",
      "1    1403980\n",
      "0     318523\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# time to clean up the data starting with SUB1_D \n",
    "# alcohol could be a success, mmj could be a success\n",
    "for value in df1['SUB1_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(14, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(16, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(18, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(12, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(13, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(2, 1)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(3, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(4, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(5, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(6, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(7, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(8, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(9, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(10, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(11, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(15, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(17, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB1'] = df1['SUB1'].replace(14, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(16, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(18, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(12, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(13, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(2, 1)\n",
    "df1['SUB1'] = df1['SUB1'].replace(3, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(4, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(5, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(6, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(7, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(8, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(9, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(10, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(11, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(15, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(17, 0)\n",
    "df1['SUB1'] = df1['SUB1'].replace(19, 0)\n",
    "\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(14, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(16, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(18, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(12, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(13, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(2, 1)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(3, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(4, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(5, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(6, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(7, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(8, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(9, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(10, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(11, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(15, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(17, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB2'] = df1['SUB2'].replace(14, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(16, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(18, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(12, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(13, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(2, 1)\n",
    "df1['SUB2'] = df1['SUB2'].replace(3, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(4, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(5, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(6, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(7, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(8, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(9, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(10, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(11, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(15, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(17, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(19, 0)\n",
    "\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(14, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(16, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(18, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(12, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(13, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(2, 1)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(3, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(4, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(5, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(6, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(7, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(8, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(9, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(10, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(11, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(15, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(17, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(19, 0)\n",
    "\n",
    "df1['SUB3'] = df1['SUB3'].replace(14, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(16, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(18, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(12, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(13, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(2, 1)\n",
    "df1['SUB3'] = df1['SUB3'].replace(3, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(4, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(5, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(6, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(7, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(8, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(9, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(10, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(11, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(15, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(17, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(19, 0)\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB1']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "for value in df1['SUB2_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB2']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "for value in df1['SUB3_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "for value in df1['SUB3']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1'] = df1['SUB1'].replace(-9, 0)\n",
    "df1['SUB1_D'] = df1['SUB1_D'].replace(-9, 0)\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 0)\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 0)\n",
    "df1['SUB3'] = df1['SUB3'].replace(-9, 0)\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "print(df1['SUB1'].value_counts())\n",
    "print(df1['SUB1_D'].value_counts())\n",
    "print(df1['SUB2'].value_counts())\n",
    "print(df1['SUB2_D'].value_counts())\n",
    "print(df1['SUB3'].value_counts())\n",
    "print(df1['SUB3_D'].value_counts())\n",
    "\n",
    "# df1['SUB1_D'].notna().value_counts()\n",
    "# # In column SUB2 replace -9 with 19\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 19)\n",
    "# print(df1['SUB2'].value_counts())\n",
    "# # In column SUB2_D replace -9 with 19\n",
    "# # df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 19)\n",
    "# print(df1['SUB2_D'].value_counts())\n",
    "# # In column SUB3 replace -9 with 19\n",
    "# # df1['SUB3'] = df1['SUB3'].replace(-9, 19)\n",
    "# print(df1['SUB3'].value_counts())\n",
    "# # In column SUB3_D replace -9 with 0\n",
    "# # df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "# print(df1['SUB3_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1_D, FREQ2_D, FREQ3_D\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1_D'] = df1['FREQ1_D'].replace(-9, 1)\n",
    "df1['FREQ2_D'] = df1['FREQ2_D'].replace(-9, 1)\n",
    "df1['FREQ3_D'] = df1['FREQ3_D'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1, FREQ2, FREQ3\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1'] = df1['FREQ1'].replace(-9, 1)\n",
    "df1['FREQ2'] = df1['FREQ2'].replace(-9, 1)\n",
    "df1['FREQ3'] = df1['FREQ3'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'CASEID'\n",
    "df1['CASEID'].notna().value_counts()\n",
    "# CASEID has no null values and does need info filled\n",
    "# we can drop this field\n",
    "df1 = df1.drop(columns=\"CASEID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'AGE'\n",
    "df1['AGE'].notna().value_counts()\n",
    "# AGE has no null values and does need info filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'GENDER'\n",
    "# gender is not a columns where we can fill in the data and not decrease the accuracy. so for all -9 values I am replacing with 0\n",
    "df1['GENDER'] = df1['GENDER'].replace(-9, 0)\n",
    "df1['GENDER'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DISYR'\n",
    "df1['DISYR'].notna().value_counts()\n",
    "# DISYR has no null values and does need info filled\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DISYR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RACE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'RACE'\n",
    "# for race, '7' indicateds 'other single race  so for all -9 values i replaces them with 7\n",
    "df1['RACE'] = df1['RACE'].replace(-9, 7)\n",
    "df1['RACE'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETHNIC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'ETHNIC'\n",
    "# for ETHNIC, '4' indicateds 'other single race  so for all -9 values I replaced them with 4\n",
    "df1['ETHNIC'] = df1['ETHNIC'].replace(-9, 4)\n",
    "df1['ETHNIC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARSTAT\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'MARSTAT'\n",
    "# for MARSTAT, hard to determine what to fill -9 with so filling with 0 for now\n",
    "df1['MARSTAT'] = df1['MARSTAT'].replace(-9, 0)\n",
    "df1['MARSTAT'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDUC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EDUC'\n",
    "# for EDUC, hard to determine what to fill -9 with. options are 1-5 so filling with 2 as it seems like a fair average\n",
    "df1['EDUC'] = df1['EDUC'].replace(-9, 2)\n",
    "df1['EDUC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMPLOY\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EMPLOY' and 'EMPLOY_D'\n",
    "# for EMPLOY, hard to determine what to fill -9 with. options are 1-4. filling with 2 for now since if the data is missing is seems like that would indicate 'unemployed'\n",
    "df1['EMPLOY'] = df1['EMPLOY'].replace(-9, 0)\n",
    "df1['EMPLOY_D'] = df1['EMPLOY_D'].replace(-9, 0)\n",
    "df1['EMPLOY'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DETNLF' and 'DETNLF_D'\n",
    "# for DETNLF, its just details on the previous columns not in labor force option so im replacing missing values with 0 as to not affect the results as much. we may want to drop this column\n",
    "# df1['DETNLF'] = df1['DETNLF'].replace(-9, 0)\n",
    "# df1['DETNLF_D'] = df1['DETNLF_D'].replace(-9, 0)\n",
    "# df1['DETNLF'].notna().value_counts()\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DETNLF\")\n",
    "df1 = df1.drop(columns=\"DETNLF_D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREG\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PREG'\n",
    "# for PREG, -9 most likely indicates male patients. replacing with 0 as to not affect the results as much. \n",
    "df1['PREG'] = df1['PREG'].replace(-9, 2)\n",
    "df1['PREG'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VET\n",
       "2    1679845\n",
       "1      42658\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'VET'\n",
    "# for VET, -9 most likely indicates not a veteren so im replacing -9 with 2 for 'no'\n",
    "df1['VET'] = df1['VET'].replace(-9, 2)\n",
    "df1['VET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIVARAG\n",
       "3    1013787\n",
       "1     436264\n",
       "2     272452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'LIVARAG'\n",
    "# for LIVARAG, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['LIVARAG'] = df1['LIVARAG'].replace(-9, 1)\n",
    "df1['LIVARAG_D'] = df1['LIVARAG_D'].replace(-9, 1)\n",
    "df1['LIVARAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMINC\n",
       "4    855478\n",
       "5    397327\n",
       "1    312986\n",
       "2     81605\n",
       "3     75107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PRIMINC'\n",
    "# for PRIMINC, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['PRIMINC'] = df1['PRIMINC'].replace(-9, 4)\n",
    "df1['PRIMINC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARRESTS_D\n",
       "0    1643399\n",
       "1      61908\n",
       "2      17196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'ARRESTS' and 'ARRESTS_D'\n",
    "# for 'ARRESTS' and 'ARRESTS_D', 0 indicates none so im setting -9 to none as that seems most likely to be the case if the information is missing\n",
    "df1['ARRESTS'] = df1['ARRESTS'].replace(-9, 0)\n",
    "df1['ARRESTS_D'] = df1['ARRESTS_D'].replace(-9, 0)\n",
    "df1['ARRESTS'].value_counts()\n",
    "df1['ARRESTS_D'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with ' STFIPS'\n",
    "# for ' STFIPS', there are no null values in this column but we may want to remove it because the large values could through the accuracy off\n",
    "df1['STFIPS'].notna().value_counts()\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"STFIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGION\n",
       "1    532413\n",
       "3    505555\n",
       "4    378260\n",
       "2    303497\n",
       "0      2778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'REGION'\n",
    "# for 'REGION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['REGION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "2    372934\n",
       "5    331617\n",
       "8    229376\n",
       "1    159479\n",
       "4    152327\n",
       "3    151170\n",
       "9    148884\n",
       "6    100660\n",
       "7     73278\n",
       "0      2778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DIVISION'\n",
    "# for 'DIVISION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERVICES_D\n",
       "7    884266\n",
       "2    240303\n",
       "6    235771\n",
       "4    179737\n",
       "5    121470\n",
       "1     43446\n",
       "8     13267\n",
       "3      4243\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'SERVICES and SERVICES_D'\n",
    "# for 'SERVICES and SERVICES_D', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data for the questions we are trying to answer\n",
    "df1['SERVICES'].value_counts()\n",
    "df1['SERVICES_D'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYWAIT\n",
       "0    1469735\n",
       "1     175018\n",
       "2      34722\n",
       "3      26618\n",
       "4      16410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DAYWAIT'\n",
    "# for 'DAYWAIT', its seems safe to replace a value of missing data with a value of '0' to indicate that they didnt wait\n",
    "df1['DAYWAIT'] = df1['DAYWAIT'].replace(-9, 0)\n",
    "df1['DAYWAIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHUSE\n",
       "2    1327459\n",
       "1     216239\n",
       "0     178805\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'METHUSE'\n",
    "# for 'METHUSE', its seems safe to replace a value of missing data with a value of 'none'\n",
    "df1['METHUSE'] = df1['METHUSE'].replace(-9, 0)\n",
    "df1['METHUSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'LOS'\n",
    "# for 'LOS', stands for length of stay this data seems irrelivent to the questions we are trying to answer so I suggest dropping the column to perserve prediction accuracy\n",
    "# 1-30, 31-45, 46-60, 61-90, 91-120, 121-180, 181-365, more than\n",
    "def los_to_category(days):\n",
    "    if days <= 30:\n",
    "        return 1\n",
    "    elif days <= 31:\n",
    "        return 2\n",
    "    elif days <= 32:\n",
    "        return 3\n",
    "    elif days <= 33:\n",
    "        return 4\n",
    "    elif days <= 34:\n",
    "        return 5\n",
    "    elif days <= 35:\n",
    "        return 6\n",
    "    elif days <= 36:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "# Test cases\n",
    "\n",
    "# df1['LOS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(los_to_category(15))  # Expected output: 1\n",
    "print(los_to_category(35))  # Expected output: 2\n",
    "print(los_to_category(50))  # Expected output: 3\n",
    "print(los_to_category(70))  # Expected output: 4\n",
    "print(los_to_category(100))  # Expected output: 5\n",
    "print(los_to_category(150))  # Expected output: 6\n",
    "print(los_to_category(200))  # Expected output: 7\n",
    "print(los_to_category(400))  # Expected output: 8\n",
    "print(los_to_category(-5))  # Expected output: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['LOS'] = df1['LOS'].apply(los_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOS\n",
       "1    934659\n",
       "4    140555\n",
       "7    128974\n",
       "5    114387\n",
       "6    114266\n",
       "2    111830\n",
       "8     93500\n",
       "3     84332\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['LOS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with PSOURCE: Referral source\n",
    "# for 'PSOURCE' this doesnt seem to me to be relevant data so im replacing -9 with 1 for now to indicate that it was self motivated\n",
    "df1['PSOURCE'] = df1['PSOURCE'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with DETCRIM: Detailed criminal justice referral\n",
    "# for 'DETCRIM' im replacing -9 with 0 for now. most of this data is missing. we may want to drop this column\n",
    "df1['DETCRIM'] = df1['DETCRIM'].replace(-9, 0)\n",
    "# drop this column\n",
    "df1 = df1.drop(columns=\"DETCRIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with NOPRIOR: Previous substance use treatment episodes\n",
    "# for 'NOPRIOR' im replacing -9 with 0 for now. its could go either way. we will ask clients\n",
    "df1['NOPRIOR'] = df1['NOPRIOR'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with ROUTE1: Route of administration (primary)\n",
    "# time to clean up the data with ROUTE2: Route of administration (secondary)\n",
    "# time to clean up the data with ROUTE3: Route of administration (tertiary)\n",
    "# for 'ROUTE1' im replacing -9 with 5 for now to indicate 'other'. its could go either way. we will ask clients\n",
    "df1['ROUTE1'] = df1['ROUTE1'].replace(-9, 5)\n",
    "df1['ROUTE2'] = df1['ROUTE2'].replace(-9, 5)\n",
    "df1['ROUTE3'] = df1['ROUTE3'].replace(-9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRSTUSE2\n",
      "3    1067078\n",
      "2     170892\n",
      "4     153705\n",
      "7     103384\n",
      "5      95617\n",
      "6      78339\n",
      "1      53488\n",
      "Name: count, dtype: int64\n",
      "FRSTUSE3\n",
      "3    1464306\n",
      "2      78630\n",
      "4      57055\n",
      "7      37209\n",
      "5      32205\n",
      "6      27655\n",
      "1      25443\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# time to clean up the data with FRSTUSE1: Age at first use (primary)\n",
    "# FRSTUSE1 is a column where its hard to determine what a value of -9 should be replaced with so im replacing it with 0 for now to have less of an impact on the data\n",
    "df1['FRSTUSE1'] = df1['FRSTUSE1'].replace(-9, 3)\n",
    "# adding Beau's code\n",
    "# In column FRSTUSE2 replace -9 with 0\n",
    "df1['FRSTUSE2'] = df1['FRSTUSE2'].replace(-9, 3)\n",
    "print(df1['FRSTUSE2'].value_counts())\n",
    "# In column FRSTUSE3 replace -9 with 0\n",
    "df1['FRSTUSE3'] = df1['FRSTUSE3'].replace(-9, 3)\n",
    "print(df1['FRSTUSE3'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB2\n",
      "1    959459\n",
      "0    763044\n",
      "Name: count, dtype: int64\n",
      "SUB2_D\n",
      "1    990170\n",
      "0    732333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column SUB2 replace -9 with 19\n",
    "df1['SUB2'] = df1['SUB2'].replace(-9, 19)\n",
    "print(df1['SUB2'].value_counts())\n",
    "# In column SUB2_D replace -9 with 19\n",
    "df1['SUB2_D'] = df1['SUB2_D'].replace(-9, 19)\n",
    "print(df1['SUB2_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB3\n",
      "1    1278583\n",
      "0     443920\n",
      "Name: count, dtype: int64\n",
      "SUB3_D\n",
      "1    1403980\n",
      "0     318523\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column SUB3 replace -9 with 19\n",
    "df1['SUB3'] = df1['SUB3'].replace(-9, 19)\n",
    "print(df1['SUB3'].value_counts())\n",
    "# In column SUB3_D replace -9 with 0\n",
    "df1['SUB3_D'] = df1['SUB3_D'].replace(-9, 0)\n",
    "print(df1['SUB3_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUTE3\n",
      "5    1365958\n",
      "2     154215\n",
      "1     122303\n",
      "3      48044\n",
      "4      31983\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column ROUTE3 replace -9 with 0\n",
    "df1['ROUTE3'] = df1['ROUTE3'].replace(-9, 0)\n",
    "print(df1['ROUTE3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSMCRIT\n",
      "5     790823\n",
      "4     289535\n",
      "8     143441\n",
      "19    125445\n",
      "7      82105\n",
      "6      56213\n",
      "9      52972\n",
      "2      40101\n",
      "10     39565\n",
      "3      29130\n",
      "11     23297\n",
      "12     17972\n",
      "1      12628\n",
      "13      7786\n",
      "15      5239\n",
      "17      2246\n",
      "14      2181\n",
      "16      1490\n",
      "18       334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column DSMCRIT replace -9 with 0\n",
    "df1['DSMCRIT'] = df1['DSMCRIT'].replace(-9, 5)\n",
    "print(df1['DSMCRIT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSYPROB\n",
      "1    899280\n",
      "2    823223\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column PSYPROB replace -9 with 1\n",
    "df1['PSYPROB'] = df1['PSYPROB'].replace(-9, 1)\n",
    "print(df1['PSYPROB'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMPAY\n",
      "1    1038444\n",
      "4     389616\n",
      "5     162022\n",
      "7      49127\n",
      "2      44071\n",
      "6      20758\n",
      "3      18465\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column PRIMPAY replace -9 with 1\n",
    "df1['PRIMPAY'] = df1['PRIMPAY'].replace(-9, 1)\n",
    "print(df1['PRIMPAY'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ_ATND_SELF_HELP\n",
      "1    1037604\n",
      "3     389036\n",
      "4     126267\n",
      "2     104522\n",
      "5      65074\n",
      "Name: count, dtype: int64\n",
      "FREQ_ATND_SELF_HELP_D\n",
      "1    859331\n",
      "3    452977\n",
      "4    186509\n",
      "2    115895\n",
      "5    107791\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In column FREQ_ATND_SELF_HELP replace -9 with 0\n",
    "df1['FREQ_ATND_SELF_HELP'] = df1['FREQ_ATND_SELF_HELP'].replace(-9, 3)\n",
    "print(df1['FREQ_ATND_SELF_HELP'].value_counts())\n",
    "# In column FREQ_ATND_SELF_HELP_D replace -9 with 0\n",
    "df1['FREQ_ATND_SELF_HELP_D'] = df1['FREQ_ATND_SELF_HELP_D'].replace(-9, 3)\n",
    "print(df1['FREQ_ATND_SELF_HELP_D'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALCFLG       0.025359\n",
       "LIVARAG_D    0.026111\n",
       "FREQ1_D      0.029926\n",
       "HLTHINS      0.032940\n",
       "ROUTE3       0.036662\n",
       "EMPLOY_D     0.040257\n",
       "ETHNIC       0.057235\n",
       "SUB1_D       0.066446\n",
       "PRIMPAY      0.067499\n",
       "AGE          0.068791\n",
       "ROUTE2       0.071289\n",
       "SUB1         0.073811\n",
       "SUB2         0.080155\n",
       "SUB3_D       0.088915\n",
       "METHUSE      0.096050\n",
       "SUB3         0.102280\n",
       "DIVISION     0.128182\n",
       "SUB2_D       0.136620\n",
       "REGION       0.153238\n",
       "REASON       1.000000\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason = df1['REASON']\n",
    "df1_corr = df1.corr()\n",
    "df1_corr.unstack().sort_values()\n",
    "variable = df1_corr['REASON'].sort_values()\n",
    "variable.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe with only the top correlated farctors left\n",
    "trimmed = df1[['SUB1_D', 'FREQ1_D', 'ARRESTS', 'ARRESTS_D', 'LIVARAG', 'EMPLOY_D', 'LIVARAG_D', 'EDUC', 'SUB1', 'FREQ_ATND_SELF_HELP', 'EMPLOY', 'ROUTE1', 'IDU', 'SERVICES', 'SERVICES_D', 'VET', 'FRSTUSE1', 'MARSTAT', 'REASON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"REASON\"]\n",
    "X = df1.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model(LinearRegression(), data)\n",
    "# test_model(KNeighborsRegressor(), data)\n",
    "# test_model(RandomForestRegressor(), data)\n",
    "# test_model(ExtraTreesRegressor(), data)\n",
    "# test_model(AdaBoostRegressor(), data)\n",
    "# test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"REASON\"]\n",
    "X = df1.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# logistic_regression_model = ExtraTreesRegressor()\n",
    "# logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "# train = (f\"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}\")\n",
    "# test = (f\"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}\")\n",
    "# testing_predictions = logistic_regression_model.predict(X_test)\n",
    "# print(accuracy_score(y_test, testing_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Beau's solution to the accuracy problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALCFLG       0.025359\n",
       "LIVARAG_D    0.026111\n",
       "FREQ1_D      0.029926\n",
       "HLTHINS      0.032940\n",
       "ROUTE3       0.036662\n",
       "EMPLOY_D     0.040257\n",
       "ETHNIC       0.057235\n",
       "SUB1_D       0.066446\n",
       "PRIMPAY      0.067499\n",
       "AGE          0.068791\n",
       "ROUTE2       0.071289\n",
       "SUB1         0.073811\n",
       "SUB2         0.080155\n",
       "SUB3_D       0.088915\n",
       "METHUSE      0.096050\n",
       "SUB3         0.102280\n",
       "DIVISION     0.128182\n",
       "SUB2_D       0.136620\n",
       "REGION       0.153238\n",
       "REASON       1.000000\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason = df1['REASON']\n",
    "df1_corr = df1.corr()\n",
    "df1_corr.unstack().sort_values()\n",
    "variable = df1_corr['REASON'].sort_values()\n",
    "variable.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSA2010</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>MARSTAT</th>\n",
       "      <th>SERVICES</th>\n",
       "      <th>LOS</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>NOPRIOR</th>\n",
       "      <th>ARRESTS</th>\n",
       "      <th>EMPLOY</th>\n",
       "      <th>METHUSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRNQFLG</th>\n",
       "      <th>BARBFLG</th>\n",
       "      <th>SEDHPFLG</th>\n",
       "      <th>INHFLG</th>\n",
       "      <th>OTCFLG</th>\n",
       "      <th>OTHERFLG</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>IDU</th>\n",
       "      <th>ALCDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722498</th>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722499</th>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722500</th>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722501</th>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722502</th>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1722503 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CBSA2010  EDUC  MARSTAT  SERVICES  LOS  PSOURCE  NOPRIOR  ARRESTS  \\\n",
       "0              -9     4        1         7    8        1        0        0   \n",
       "1              -9     3        1         7    6        1        0        0   \n",
       "2              -9     2        1         7    6        1        0        0   \n",
       "3              -9     3        1         7    8        1        1        0   \n",
       "4              -9     3        3         7    8        1        1        0   \n",
       "...           ...   ...      ...       ...  ...      ...      ...      ...   \n",
       "1722498        -9     4        2         7    4        1        0        0   \n",
       "1722499        -9     3        3         7    1        7        0        0   \n",
       "1722500        -9     2        1         6    4        1        0        0   \n",
       "1722501        -9     1        1         7    1        7        0        0   \n",
       "1722502        -9     2        4         7    1        1        0        0   \n",
       "\n",
       "         EMPLOY  METHUSE  ...  TRNQFLG  BARBFLG  SEDHPFLG  INHFLG  OTCFLG  \\\n",
       "0             2        2  ...        0        0         0       0       0   \n",
       "1             1        2  ...        0        0         0       0       0   \n",
       "2             4        2  ...        0        0         0       0       0   \n",
       "3             3        2  ...        0        0         0       0       0   \n",
       "4             4        2  ...        0        0         0       0       0   \n",
       "...         ...      ...  ...      ...      ...       ...     ...     ...   \n",
       "1722498       1        2  ...        0        0         0       0       0   \n",
       "1722499       4        2  ...        0        0         0       0       0   \n",
       "1722500       3        2  ...        0        0         0       0       0   \n",
       "1722501       4        2  ...        0        0         0       0       0   \n",
       "1722502       1        2  ...        0        0         0       0       0   \n",
       "\n",
       "         OTHERFLG  DIVISION  REGION  IDU  ALCDRUG  \n",
       "0               0         9       4    0        1  \n",
       "1               0         9       4    0        3  \n",
       "2               0         9       4    0        3  \n",
       "3               0         9       4    0        3  \n",
       "4               0         9       4    0        1  \n",
       "...           ...       ...     ...  ...      ...  \n",
       "1722498         0         8       4    0        1  \n",
       "1722499         0         8       4    0        2  \n",
       "1722500         0         8       4    0        2  \n",
       "1722501         0         8       4    0        3  \n",
       "1722502         0         8       4    0        1  \n",
       "\n",
       "[1722503 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display df1\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of REASON with other variables.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROUTE1       0.024558\n",
       "ALCFLG       0.025359\n",
       "LIVARAG_D    0.026111\n",
       "FREQ1_D      0.029926\n",
       "HLTHINS      0.032940\n",
       "ROUTE3       0.036662\n",
       "EMPLOY_D     0.040257\n",
       "ETHNIC       0.057235\n",
       "SUB1_D       0.066446\n",
       "PRIMPAY      0.067499\n",
       "AGE          0.068791\n",
       "ROUTE2       0.071289\n",
       "SUB1         0.073811\n",
       "SUB2         0.080155\n",
       "SUB3_D       0.088915\n",
       "METHUSE      0.096050\n",
       "SUB3         0.102280\n",
       "DIVISION     0.128182\n",
       "SUB2_D       0.136620\n",
       "REGION       0.153238\n",
       "REASON       1.000000\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What columns are highly correlated with the target variable 'REASON'?\n",
    "high_corr_df = df1_corr['REASON'].sort_values()\n",
    "print('Correlation of REASON with other variables.')\n",
    "display(high_corr_df.tail(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Training Accuracy: 0.7882601041217647\n",
      "RandomForest Testing Accuracy: 0.787161720865832\n",
      "ExtraTrees Training Accuracy: 0.7665141269751423\n",
      "ExtraTrees Testing Accuracy: 0.7649905225238823\n"
     ]
    }
   ],
   "source": [
    "# Drop the target variable 'REASON' from the dataset\n",
    "X = df1.drop(columns='REASON')\n",
    "y = df1['REASON']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=4, random_state=42)\n",
    "et_model = ExtraTreesClassifier(n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=4, random_state=42)\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the training set\n",
    "# y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# # Calculate the training accuracy\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# # Make predictions on the testing set\n",
    "# y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# # Calculate the testing accuracy\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# # Print the accuracies\n",
    "# print('Training Accuracy:', train_accuracy)\n",
    "# print('Testing Accuracy:', test_accuracy)\n",
    "\n",
    "# Train the RandomForest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the RandomForest model\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the RandomForest accuracies\n",
    "train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print the RandomForest accuracies\n",
    "print('RandomForest Training Accuracy:', train_accuracy_rf)\n",
    "print('RandomForest Testing Accuracy:', test_accuracy_rf)\n",
    "\n",
    "# Train the ExtraTrees model\n",
    "et_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the ExtraTrees model\n",
    "y_train_pred_et = et_model.predict(X_train)\n",
    "y_test_pred_et = et_model.predict(X_test)\n",
    "\n",
    "# Calculate the ExtraTrees accuracies\n",
    "train_accuracy_et = accuracy_score(y_train, y_train_pred_et)\n",
    "test_accuracy_et = accuracy_score(y_test, y_test_pred_et)\n",
    "\n",
    "# Print the ExtraTrees accuracies\n",
    "print('ExtraTrees Training Accuracy:', train_accuracy_et)\n",
    "print('ExtraTrees Testing Accuracy:', test_accuracy_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Training Accuracy: 0.7882601041217647\n",
      "RandomForest Testing Accuracy: 0.787161720865832\n",
      "RandomForest is overfitting.\n",
      "ExtraTrees Training Accuracy: 0.7665141269751423\n",
      "ExtraTrees Testing Accuracy: 0.7649905225238823\n",
      "ExtraTrees is overfitting.\n"
     ]
    }
   ],
   "source": [
    "# Print the RandomForest accuracies\n",
    "print('RandomForest Training Accuracy:', train_accuracy_rf)\n",
    "print('RandomForest Testing Accuracy:', test_accuracy_rf)\n",
    "\n",
    "# Check for overfitting and underfitting in RandomForest\n",
    "if train_accuracy_rf > test_accuracy_rf:\n",
    "    print('RandomForest is overfitting.')\n",
    "elif train_accuracy_rf < test_accuracy_rf:\n",
    "    print('RandomForest is underfitting.')\n",
    "else:\n",
    "    print('RandomForest is fitting well.')\n",
    "\n",
    "# Print the ExtraTrees accuracies\n",
    "print('ExtraTrees Training Accuracy:', train_accuracy_et)\n",
    "print('ExtraTrees Testing Accuracy:', test_accuracy_et)\n",
    "\n",
    "# Check for overfitting and underfitting in ExtraTrees\n",
    "if train_accuracy_et > test_accuracy_et:\n",
    "    print('ExtraTrees is overfitting.')\n",
    "elif train_accuracy_et < test_accuracy_et:\n",
    "    print('ExtraTrees is underfitting.')\n",
    "else:\n",
    "    print('ExtraTrees is fitting well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Cross-Validation Accuracy: 0.7866280319297335\n",
      "ExtraTrees Cross-Validation Accuracy: 0.7629836538765005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation on the RandomForest model\n",
    "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "print('RandomForest Cross-Validation Accuracy:', np.mean(rf_scores))\n",
    "\n",
    "# Perform cross-validation on the ExtraTrees model\n",
    "et_scores = cross_val_score(et_model, X_train, y_train, cv=5)\n",
    "print('ExtraTrees Cross-Validation Accuracy:', np.mean(et_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to visualize the decision tree for the above classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initial imports\n",
    "# import pandas as pd\n",
    "# from sklearn import tree\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Needed for decision tree visualization\n",
    "# import pydotplus\n",
    "# from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Define features set\n",
    "# df_final = df1.copy()\n",
    "# Xnew = df_final.copy()\n",
    "# Xnew.drop(\"outcome\", axis=1, inplace=True)\n",
    "# Xnew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define target vector\n",
    "# ynew = df_final[\"RESULT\"].values.reshape(-1, 1)\n",
    "# ynew[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Splitting into Train and Test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xnew, ynew, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the StandardScaler instance\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Fit the StandardScaler with the training data\n",
    "# X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the training data\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Create the decision tree classifier instance\n",
    "# model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Fit the model\n",
    "# model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Making predictions using the testing data\n",
    "# predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Calculate the accuracy score\n",
    "# acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DOT data\n",
    "# dot_data = tree.export_graphviz(\n",
    "#     model, out_file=None, feature_names=X.columns, class_names=[\"0\", \"1\"], filled=True\n",
    "# )\n",
    "\n",
    "# # Draw graph\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# # Show graph\n",
    "# Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
