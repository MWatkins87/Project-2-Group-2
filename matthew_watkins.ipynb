{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISYR</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>CBSA2010</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>MARSTAT</th>\n",
       "      <th>SERVICES</th>\n",
       "      <th>DETCRIM</th>\n",
       "      <th>LOS</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRNQFLG</th>\n",
       "      <th>BARBFLG</th>\n",
       "      <th>SEDHPFLG</th>\n",
       "      <th>INHFLG</th>\n",
       "      <th>OTCFLG</th>\n",
       "      <th>OTHERFLG</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>IDU</th>\n",
       "      <th>ALCDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191553576</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191465214</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191443889</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191409377</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191479567</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISYR       CASEID  STFIPS  CBSA2010  EDUC  MARSTAT  SERVICES  DETCRIM  \\\n",
       "0   2019  20191553576       2        -9     4        1         7       -9   \n",
       "1   2019  20191465214       2        -9     3        1         7       -9   \n",
       "2   2019  20191443889       2        -9     2        1         7       -9   \n",
       "3   2019  20191409377       2        -9     3        1         7       -9   \n",
       "4   2019  20191479567       2        -9     3        3         7       -9   \n",
       "\n",
       "   LOS  PSOURCE  ...  TRNQFLG  BARBFLG  SEDHPFLG  INHFLG  OTCFLG  OTHERFLG  \\\n",
       "0   37        1  ...        0        0         0       0       0         0   \n",
       "1   35        1  ...        0        0         0       0       0         0   \n",
       "2   35        1  ...        0        0         0       0       0         0   \n",
       "3   37        1  ...        0        0         0       0       0         0   \n",
       "4   37        1  ...        0        0         0       0       0         0   \n",
       "\n",
       "   DIVISION  REGION  IDU  ALCDRUG  \n",
       "0         9       4    0        1  \n",
       "1         9       4    0        3  \n",
       "2         9       4    0        3  \n",
       "3         9       4    0        3  \n",
       "4         9       4    0        1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tedsd_puf_2019.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASON\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "# from conversation with \"house of Hope recovery\" class 4 which is \"transfer to a different facility\" would also be considered a success.\n",
    "for value in df1['REASON']:\n",
    "    if value == 1:\n",
    "        value = value\n",
    "    elif value == 4:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['REASON'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUB1_D\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data starting with SUB1_D \n",
    "# alcohol could be a success, mmj could be a success\n",
    "\n",
    "for value in df1['SUB1_D']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1_D'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUB1_D\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data starting with SUB1 \n",
    "# alcohol could be a success, mmj could be a success, using the same values for SUB1_D\n",
    "\n",
    "for value in df1['SUB1']:\n",
    "    if value == 1 or value == 14 or value == 16 or value == 18 or value == 12 or value == 13 or value == 2:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "df1['SUB1_D'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARRESTS\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data starting with ARRESTS and ARRESTS_D \n",
    "# alcohol could be a success, mmj could be a success\n",
    "\n",
    "for value in df1['ARRESTS']:\n",
    "    if value == -9:\n",
    "        value = 0\n",
    "    else:\n",
    "        value = value\n",
    "for value in df1['ARRESTS_D']:\n",
    "    if value == -9:\n",
    "        value = 0\n",
    "    else:\n",
    "        value = value\n",
    "df1['ARRESTS'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1_D, FREQ2_D, FREQ3_D\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1_D'] = df1['FREQ1_D'].replace(-9, 1)\n",
    "df1['FREQ2_D'] = df1['FREQ2_D'].replace(-9, 1)\n",
    "df1['FREQ3_D'] = df1['FREQ3_D'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FREQ1, FREQ2, FREQ3\n",
    "# replacing -9 in the columns with 1 since 1 indicates 'no use' and if data was missing we assumed it was irrelivent to begin with\n",
    "df1['FREQ1'] = df1['FREQ1'].replace(-9, 1)\n",
    "df1['FREQ2'] = df1['FREQ2'].replace(-9, 1)\n",
    "df1['FREQ3'] = df1['FREQ3'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASEID\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'CASEID'\n",
    "df1['CASEID'].notna().value_counts()\n",
    "# CASEID has no null values and does need info filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'AGE'\n",
    "df1['AGE'].notna().value_counts()\n",
    "# AGE has no null values and does need info filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'GENDER'\n",
    "# gender is not a columns where we can fill in the data and not decrease the accuracy. so for all -9 values I am replacing with 0\n",
    "df1['GENDER'] = df1['GENDER'].replace(-9, 0)\n",
    "df1['GENDER'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DISYR'\n",
    "df1['DISYR'].notna().value_counts()\n",
    "# DISYR has no null values and does need info filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RACE\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'RACE'\n",
    "# for race, '7' indicateds 'other single race  so for all -9 values i replaces them with 7\n",
    "df1['RACE'] = df1['RACE'].replace(-9, 7)\n",
    "df1['RACE'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETHNIC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'ETHNIC'\n",
    "# for ETHNIC, '4' indicateds 'other single race  so for all -9 values I replaced them with 4\n",
    "df1['ETHNIC'] = df1['ETHNIC'].replace(-9, 4)\n",
    "df1['ETHNIC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARSTAT\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'MARSTAT'\n",
    "# for MARSTAT, hard to determine what to fill -9 with so filling with 0 for now\n",
    "df1['MARSTAT'] = df1['MARSTAT'].replace(-9, 0)\n",
    "df1['MARSTAT'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDUC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EDUC'\n",
    "# for MARSTAT, hard to determine what to fill -9 with. options are 1-5 so filling with 2 as it seems like a fair average\n",
    "df1['EDUC'] = df1['EDUC'].replace(-9, 2)\n",
    "df1['EDUC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMPLOY\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'EMPLOY' and 'EMPLOY_D'\n",
    "# for EMPLOY, hard to determine what to fill -9 with. options are 1-4. filling with 2 for now since if the data is missing is seems like that would indicate 'unemployed'\n",
    "df1['EMPLOY'] = df1['EMPLOY'].replace(-9, 2)\n",
    "df1['EMPLOY_D'] = df1['EMPLOY_D'].replace(-9, 2)\n",
    "df1['EMPLOY'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DETNLF\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DETNLF' and 'DETNLF_D'\n",
    "# for DETNLF, its just details on the previous columns not in labor force option so im replacing missing values with 0 as to not affect the results as much. we may want to drop this column\n",
    "df1['DETNLF'] = df1['DETNLF'].replace(-9, 0)\n",
    "df1['DETNLF_D'] = df1['DETNLF_D'].replace(-9, 0)\n",
    "df1['DETNLF'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREG\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PREG'\n",
    "# for PREG, -9 most likely indicates male patients. replacing with 0 as to not affect the results as much. \n",
    "df1['PREG'] = df1['PREG'].replace(-9, 0)\n",
    "df1['PREG'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VET\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'VET'\n",
    "# for VET, -9 most likely indicates not a veteren so im replacing -9 with 2 for 'no'\n",
    "df1['VET'] = df1['VET'].replace(-9, 2)\n",
    "df1['VET'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIVARAG\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'LIVARAG'\n",
    "# for LIVARAG, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['LIVARAG'] = df1['LIVARAG'].replace(-9, 0)\n",
    "df1['LIVARAG_D'] = df1['LIVARAG_D'].replace(-9, 0)\n",
    "df1['LIVARAG'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMINC\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'PRIMINC'\n",
    "# for PRIMINC, its hard to determine what -9 could indicate so im replacing -9 with 0 as to not affect the data as much with the -9's in this column\n",
    "df1['PRIMINC'] = df1['PRIMINC'].replace(-9, 0)\n",
    "df1['PRIMINC'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'ARRESTS' and 'ARRESTS_D'\n",
    "# for 'ARRESTS' and 'ARRESTS_D', 0 indicates none so im setting -9 to none as that seems most likely to be the case if the information is missing\n",
    "df1['ARRESTS'] = df1['ARRESTS'].replace(-9, 0)\n",
    "df1['ARRESTS_D'] = df1['ARRESTS_D'].replace(-9, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STFIPS\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with ' STFIPS'\n",
    "# for ' STFIPS', there are no null values in this column but we may want to remove it because the large values could through the accuracy off\n",
    "df1['STFIPS'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGION\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'REGION'\n",
    "# for 'REGION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['REGION'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'DIVISION'\n",
    "# for 'DIVISION', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data\n",
    "df1['DIVISION'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERVICES_D\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'SERVICES and SERVICES_D'\n",
    "# for 'SERVICES and SERVICES_D', there are no null values in this column but we may want to remove it because the values could through the accuracy off and it doesnt seem to be relevant data for the questions we are trying to answer\n",
    "df1['SERVICES'].notna().value_counts()\n",
    "df1['SERVICES_D'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'DAYWAIT'\n",
    "# for 'DAYWAIT', its seems safe to replace a value of missing data with a value of '0' to indicate that they didnt wait\n",
    "df1['DAYWAIT'] = df1['DAYWAIT'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with 'METHUSE'\n",
    "# for 'METHUSE', its seems safe to replace a value of missing data with a value of 'none'\n",
    "df1['METHUSE'] = df1['METHUSE'].replace(-9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOS\n",
       "True    1722503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to clean up the data with 'LOS'\n",
    "# for 'LOS', stands for length of stay this data seems irrelivent to the questions we are trying to answer so I suggest dropping the column to perserve prediction accuracy\n",
    "df1['LOS'].notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with PSOURCE: Referral source\n",
    "# for 'PSOURCE' this doesnt seem to me to be relevant data so im replacing -9 with 1 for now to indicate that it was self motivated\n",
    "df1['PSOURCE'] = df1['PSOURCE'].replace(-9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with DETCRIM: Detailed criminal justice referral\n",
    "# for 'DETCRIM' im replacing -9 with 0 for now. most of this data is missing. we may want to drop this column\n",
    "df1['DETCRIM'] = df1['DETCRIM'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with NOPRIOR: Previous substance use treatment episodes\n",
    "# for 'NOPRIOR' im replacing -9 with 0 for now. its could go either way. we will ask clients\n",
    "df1['NOPRIOR'] = df1['NOPRIOR'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with ROUTE1: Route of administration (primary)\n",
    "# time to clean up the data with ROUTE2: Route of administration (secondary)\n",
    "# time to clean up the data with ROUTE3: Route of administration (tertiary)\n",
    "# for 'ROUTE1' im replacing -9 with 5 for now to indicate 'other'. its could go either way. we will ask clients\n",
    "df1['ROUTE1'] = df1['ROUTE1'].replace(-9, 5)\n",
    "df1['ROUTE2'] = df1['ROUTE2'].replace(-9, 5)\n",
    "df1['ROUTE3'] = df1['ROUTE3'].replace(-9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to clean up the data with FRSTUSE1: Age at first use (primary)\n",
    "# FRSTUSE1 is a column where its hard to determine what a value of -9 should be replaced with so im replacing it with 0 for now to have less of an impact on the data\n",
    "df1['FRSTUSE1'] = df1['FRSTUSE1'].replace(-9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARSTAT                0.138023\n",
       "FRSTUSE1               0.139035\n",
       "VET                    0.144566\n",
       "SERVICES_D             0.152773\n",
       "SERVICES               0.154441\n",
       "IDU                    0.155722\n",
       "ROUTE1                 0.165564\n",
       "EMPLOY                 0.177870\n",
       "FREQ_ATND_SELF_HELP    0.183493\n",
       "SUB1                   0.191675\n",
       "EDUC                   0.193754\n",
       "LIVARAG_D              0.206890\n",
       "EMPLOY_D               0.208258\n",
       "LIVARAG                0.209302\n",
       "ARRESTS_D              0.209523\n",
       "ARRESTS                0.209631\n",
       "FREQ1_D                0.214312\n",
       "SUB1_D                 0.243122\n",
       "REASON                 1.000000\n",
       "DISYR                       NaN\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason = df1['REASON']\n",
    "df1_corr = df1.corr()\n",
    "df1_corr.unstack().sort_values()\n",
    "variable = df1_corr['REASON'].sort_values()\n",
    "variable.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe with only the top correlated farctors left\n",
    "trimmed = df1[['SUB1_D', 'FREQ1_D', 'ARRESTS', 'ARRESTS_D', 'LIVARAG', 'EMPLOY_D', 'LIVARAG_D', 'EDUC', 'SUB1', 'FREQ_ATND_SELF_HELP', 'EMPLOY', 'ROUTE1', 'IDU', 'SERVICES', 'SERVICES_D', 'VET', 'FRSTUSE1', 'MARSTAT', 'REASON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trimmed[\"REASON\"]\n",
    "X = trimmed.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(LinearRegression(), data)\n",
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HLTHINS    -0.106469\n",
       "PRIMINC    -0.098816\n",
       "LOS        -0.084553\n",
       "ALCFLG     -0.078218\n",
       "PRIMPAY    -0.059634\n",
       "AGE        -0.051736\n",
       "DETNLF     -0.051458\n",
       "CASEID     -0.042650\n",
       "DIVISION   -0.030955\n",
       "DAYWAIT    -0.014194\n",
       "DETCRIM    -0.006041\n",
       "BARBFLG    -0.003555\n",
       "DSMCRIT    -0.002691\n",
       "METHUSE    -0.001831\n",
       "TRNQFLG     0.002683\n",
       "INHFLG      0.003850\n",
       "OTCFLG      0.005075\n",
       "PCPFLG      0.006215\n",
       "HALLFLG     0.007157\n",
       "REGION      0.009529\n",
       "Name: REASON, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"REASON\"]\n",
    "X = df1.copy()\n",
    "X = X.drop(columns=\"REASON\")\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "train = (f\"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}\")\n",
    "test = (f\"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}\")\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "print(accuracy_score(y_test, testing_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "# Replace -9 with NaN\n",
    "df2['FREQ1_D'] = df2['FREQ1_D'].replace(-9, 1)\n",
    "df2['FREQ2_D'] = df2['FREQ2_D'].replace(-9, 1)\n",
    "df2['FREQ3_D'] = df2['FREQ3_D'].replace(-9, 1)\n",
    "# print('Replacing -9 with NaN. A -9 represents a missing value code in the dataset.')\n",
    "# df2 = df2.replace(-9, np.nan)\n",
    "# print('Replacing -9 with NaN. A -9 represents a missing value code in the dataset.')\n",
    "\n",
    "#df2['FREQ1_D'].notna().value_counts()\n",
    "# df2['FREQ1_D'].isna()\n",
    "\n",
    "# for value in df2['FREQ1_D']:\n",
    "#     if value == \"nan\":\n",
    "#         value = 1\n",
    "#         print(value)\n",
    "#     else:\n",
    "#          value = value\n",
    "#          print(value)\n",
    "# for value in df2['FREQ2_D']:\n",
    "#     if value == 'NaN':\n",
    "#         value = 1\n",
    "#     else:\n",
    "#         value = value\n",
    "# for value in df2['FREQ3_D']:\n",
    "#     if value == 'NaN':\n",
    "#         value = 1\n",
    "#     else:\n",
    "#         value = value\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    3\n",
       "Name: FREQ3_D, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['FREQ3_D'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISYR</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>CBSA2010</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>MARSTAT</th>\n",
       "      <th>SERVICES</th>\n",
       "      <th>DETCRIM</th>\n",
       "      <th>LOS</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRNQFLG</th>\n",
       "      <th>BARBFLG</th>\n",
       "      <th>SEDHPFLG</th>\n",
       "      <th>INHFLG</th>\n",
       "      <th>OTCFLG</th>\n",
       "      <th>OTHERFLG</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>IDU</th>\n",
       "      <th>ALCDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191553576</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191465214</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191443889</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191409377</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191479567</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722498</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191743528</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722499</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191666713</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722500</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191405666</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722501</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191697509</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722502</th>\n",
       "      <td>2019</td>\n",
       "      <td>20191502624</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1722503 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DISYR       CASEID  STFIPS  CBSA2010  EDUC  MARSTAT  SERVICES  \\\n",
       "0         2019  20191553576       2       NaN   4.0      1.0         7   \n",
       "1         2019  20191465214       2       NaN   3.0      1.0         7   \n",
       "2         2019  20191443889       2       NaN   2.0      1.0         7   \n",
       "3         2019  20191409377       2       NaN   3.0      1.0         7   \n",
       "4         2019  20191479567       2       NaN   3.0      3.0         7   \n",
       "...        ...          ...     ...       ...   ...      ...       ...   \n",
       "1722498   2019  20191743528      56       NaN   4.0      2.0         7   \n",
       "1722499   2019  20191666713      56       NaN   3.0      3.0         7   \n",
       "1722500   2019  20191405666      56       NaN   2.0      1.0         6   \n",
       "1722501   2019  20191697509      56       NaN   1.0      1.0         7   \n",
       "1722502   2019  20191502624      56       NaN   NaN      4.0         7   \n",
       "\n",
       "         DETCRIM  LOS  PSOURCE  ...  TRNQFLG  BARBFLG  SEDHPFLG  INHFLG  \\\n",
       "0            NaN   37      1.0  ...        0        0         0       0   \n",
       "1            NaN   35      1.0  ...        0        0         0       0   \n",
       "2            NaN   35      1.0  ...        0        0         0       0   \n",
       "3            NaN   37      1.0  ...        0        0         0       0   \n",
       "4            NaN   37      1.0  ...        0        0         0       0   \n",
       "...          ...  ...      ...  ...      ...      ...       ...     ...   \n",
       "1722498      NaN   33      1.0  ...        0        0         0       0   \n",
       "1722499      1.0   13      7.0  ...        0        0         0       0   \n",
       "1722500      NaN   33      1.0  ...        0        0         0       0   \n",
       "1722501      3.0   14      7.0  ...        0        0         0       0   \n",
       "1722502      NaN   13      1.0  ...        0        0         0       0   \n",
       "\n",
       "         OTCFLG  OTHERFLG  DIVISION  REGION  IDU  ALCDRUG  \n",
       "0             0         0         9       4  0.0        1  \n",
       "1             0         0         9       4  0.0        3  \n",
       "2             0         0         9       4  0.0        3  \n",
       "3             0         0         9       4  0.0        3  \n",
       "4             0         0         9       4  0.0        1  \n",
       "...         ...       ...       ...     ...  ...      ...  \n",
       "1722498       0         0         8       4  0.0        1  \n",
       "1722499       0         0         8       4  0.0        2  \n",
       "1722500       0         0         8       4  0.0        2  \n",
       "1722501       0         0         8       4  0.0        3  \n",
       "1722502       0         0         8       4  0.0        1  \n",
       "\n",
       "[1722503 rows x 76 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dropna()\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
